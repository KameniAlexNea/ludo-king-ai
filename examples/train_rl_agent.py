#!/usr/bin/env python3
"""
Advanced Ludo RL Training Script

This script demonstrates comprehensive RL agent training with:
1. Enhanced state representation with 64-dimensional features
2. Dueling DQN architecture with prioritized replay
3. Advanced training pipeline with validation and early stopping
4. Model interpretation and analysis tools
5. Comprehensive evaluation and visualization
"""

import argparse
import sys
from pathlib import Path

# Add the project root to Python path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from ludo_rl.config import REWARDS, TRAINING_CONFIG
from ludo_rl.rl_player import RLPlayer
from ludo_rl.trainer import LudoRLTrainer
from ludo_rl.validator import LudoRLValidator


def display_configuration():
    """Display the current training and reward configuration."""
    print("\nâš™ï¸  Training Configuration:")
    print(f"   Hidden dimensions: {TRAINING_CONFIG.HIDDEN_DIM}")
    print(f"   Learning rate: {TRAINING_CONFIG.LEARNING_RATE}")
    print(f"   Batch size: {TRAINING_CONFIG.BATCH_SIZE}")
    print(f"   Use prioritized replay: {TRAINING_CONFIG.USE_PRIORITIZED_REPLAY}")
    print(f"   Use double DQN: {TRAINING_CONFIG.USE_DOUBLE_DQN}")

    print("\nğŸ’° Reward Configuration:")
    print(f"   Success: {REWARDS.SUCCESS}")
    print(f"   Failure: {REWARDS.FAILS}")
    print(f"   Capture: {REWARDS.CAPTURE}")
    print(f"   Token finished: {REWARDS.TOKEN_FINISHED}")


def validate_and_analyze_model(model_path, trainer):
    """Validate and analyze the trained model."""
    if not model_path.exists():
        print("   âš ï¸  Model file not found, skipping validation")
        return
    
    print("\nğŸ¤– Testing Trained Model...")
    player = RLPlayer(str(model_path), name="TrainedRLAgent")
    
    # Test model with sample data if available
    if trainer.game_data:
        sample_data = trainer.game_data[:10]  # Use first 10 samples
        
        print("\nğŸ” Model Validation Analysis...")
        try:
            validator = LudoRLValidator(str(model_path))
            analysis_results = validator.analyze_decision_patterns(sample_data)
            
            print("   Decision pattern analysis:")
            move_prefs = analysis_results.get("move_type_preferences", {})
            for move_type, count in move_prefs.items():
                print(f"     {move_type}: {count}")
            
            safety_prefs = analysis_results.get("safety_preferences", {})
            total_moves = sum(safety_prefs.values())
            if total_moves > 0:
                safe_rate = safety_prefs.get("safe", 0) / total_moves
                print(f"   Safety rate: {safe_rate:.2f}")
                
        except Exception as e:
            print(f"   âš ï¸  Validation analysis error: {e}")


def main():
    """Advanced RL training with comprehensive analysis."""
    parser = argparse.ArgumentParser(
        description="Advanced Ludo RL Agent Training",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Standard training with validation
  python train_rl_agent.py --epochs 1000 --validation-split 0.2
  
  # Advanced training with early stopping
  python train_rl_agent.py --epochs 2000 --early-stopping --patience 20
  
  # Training with custom model path
  python train_rl_agent.py --output models/custom_model.pth --epochs 1500
        """,
    )

    parser.add_argument(
        "--save-dir",
        type=Path,
        default=Path("saved_states/games"),
        help="Directory where game data is stored (default: saved_states/games)",
    )

    parser.add_argument(
        "--output",
        "--model-path",
        type=Path,
        default=Path("models/ludo_dqn_model.pth"),
        help="Path to save the trained model (default: models/ludo_dqn_model.pth)",
    )

    parser.add_argument(
        "--epochs",
        type=int,
        default=1000,
        help="Number of training epochs (default: 1000)",
    )

    parser.add_argument(
        "--validation-split",
        type=float,
        default=0.1,
        help="Fraction of data to use for validation (default: 0.1)",
    )

    parser.add_argument(
        "--early-stopping",
        action="store_true",
        help="Enable early stopping based on validation loss",
    )

    parser.add_argument(
        "--patience",
        type=int,
        default=15,
        help="Early stopping patience (default: 15)",
    )

    parser.add_argument(
        "--target-update-freq",
        type=int,
        default=100,
        help="Frequency of target network updates (default: 100)",
    )

    parser.add_argument(
        "--save-freq",
        type=int,
        default=200,
        help="Frequency of model checkpoints during training (default: 200)",
    )

    parser.add_argument(
        "--use-prioritized-replay",
        action="store_true",
        default=True,
        help="Use prioritized experience replay (default: True)",
    )

    parser.add_argument(
        "--use-double-dqn",
        action="store_true",
        default=True,
        help="Use Double DQN technique (default: True)",
    )

    args = parser.parse_args()

    print("ğŸ² Advanced Ludo RL Training System")
    print("=" * 50)

    # Create models directory if needed
    model_path = args.output
    model_path.parent.mkdir(parents=True, exist_ok=True)

    # Check for saved game data
    save_dir = args.save_dir
    if not save_dir.exists():
        print(f"âŒ No {save_dir} directory found. Please run tournaments first to generate training data.")
        print("   Example: python four_player_tournament.py")
        return

    # Find JSON files
    json_files = list(save_dir.glob("**/*.json"))
    if not json_files:
        print(f"âŒ No JSON game data found in {save_dir} directory.")
        return

    print(f"âœ… Found {len(json_files)} game data files")

    # Initialize advanced trainer
    print("\nğŸ§  Initializing Advanced RL Trainer...")
    try:
        trainer = LudoRLTrainer(
            state_saver_dir=str(save_dir),
            use_prioritized_replay=args.use_prioritized_replay,
            use_double_dqn=args.use_double_dqn,
        )

        if len(trainer.game_data) == 0:
            print("âŒ No valid training data found!")
            return

        print(f"   State dimension: {trainer.encoder.state_dim} features")
        print(f"   Training examples: {len(trainer.game_data)}")

    except Exception as e:
        print(f"âŒ Error initializing trainer: {e}")
        return

    # Display configuration
    display_configuration()

    # Display data statistics
    print("\nğŸ“ˆ Training Data Statistics:")
    strategies = {}
    outcomes = {"success": 0, "failed": 0}

    for record in trainer.game_data:
        strategy = record.get("strategy", "unknown")
        if isinstance(strategy, dict):
            strategy = strategy.get("name", "unknown")

        strategies[strategy] = strategies.get(strategy, 0) + 1

        if record.get("outcome", {}).get("success", False):
            outcomes["success"] += 1
        else:
            outcomes["failed"] += 1

    print(f"   Strategies represented: {list(strategies.keys())}")
    for strategy, count in strategies.items():
        print(f"   - {strategy}: {count} decisions")
    print(f"   Successful moves: {outcomes['success']}")
    print(f"   Failed moves: {outcomes['failed']}")

    # Train the agent with advanced features
    print(f"\nğŸ‹ï¸  Training Advanced DQN Agent for {args.epochs} epochs...")
    try:
        # Prepare training parameters
        training_params = {
            "epochs": args.epochs,
            "validation_split": args.validation_split,
            "target_update_freq": args.target_update_freq,
            "save_freq": args.save_freq,
            "model_save_path": str(model_path),
        }
        
        # Add early stopping if requested
        if args.early_stopping:
            training_params["early_stopping_patience"] = args.patience
        
        training_stats = trainer.train(**training_params)

        print("âœ… Training completed!")
        print(f"\nğŸ“Š Training Results:")
        for key, value in training_stats.items():
            if isinstance(value, float):
                print(f"   {key}: {value:.4f}")
            else:
                print(f"   {key}: {value}")

    except Exception as e:
        print(f"âŒ Error during training: {e}")
        return

    # Generate training progress plots
    print("\nï¿½ Generating Training Progress Plots...")
    try:
        plot_path = model_path.parent / "training_progress.png"
        trainer.plot_training_progress(str(plot_path))
        print(f"âœ… Training plots saved to {plot_path}")
    except Exception as e:
        print(f"âš ï¸  Could not generate plots: {e}")

    # Comprehensive model evaluation
    print("\nğŸ¯ Comprehensive Model Evaluation...")
    try:
        eval_stats = trainer.evaluate_model()
        print("âœ… Evaluation completed!")
        print(f"   Accuracy: {eval_stats.get('accuracy', 0):.2%}")
        print(f"   Avg reward per sequence: {eval_stats.get('avg_reward_per_sequence', 0):.2f}")
        print(f"   Test sequences: {eval_stats.get('num_test_sequences', 0)}")

    except Exception as e:
        print(f"âš ï¸  Error during evaluation: {e}")

    # Advanced model validation and analysis
    validate_and_analyze_model(model_path, trainer)

    print(f"\nğŸ‰ Advanced Training Complete! Model saved to: {model_path}")
    
    print("\nâœ¨ Key improvements implemented:")
    print("  âœ“ Compact 64-feature state representation")
    print("  âœ“ Dueling DQN architecture with Double DQN")
    print("  âœ“ Prioritized experience replay")
    print("  âœ“ Enhanced reward engineering")
    print("  âœ“ Validation and early stopping")
    print("  âœ“ Comprehensive model analysis")
    
    print("\nğŸ“ Generated files:")
    if model_path.exists():
        print(f"  Model: {model_path}")
    plot_path = model_path.parent / "training_progress.png"
    if plot_path.exists():
        print(f"  Training plot: {plot_path}")

    print("\nğŸ’¡ Next steps:")
    print("   1. Use the trained model in games with:")
    print("      from ludo_rl import RLPlayer")
    print("      player = RLPlayer('models/ludo_dqn_model.pth')")
    print("   2. Run tournaments to gather more diverse training data")
    print("   3. Experiment with advanced hyperparameters:")
    print(f"      python {sys.argv[0]} --epochs 2000 --validation-split 0.2 --early-stopping")
    print("   4. Use model validation tools for deeper analysis")
    
    print("\nğŸš€ Ready for production deployment!")


if __name__ == "__main__":
    main()
